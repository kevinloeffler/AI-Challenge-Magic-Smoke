{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11afed6e-38ec-4dde-9b76-aa5343ac1d7e",
   "metadata": {},
   "source": [
    "# Einleitung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393d9c47-cbe1-4301-bd75-c97f641fe35e",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "Zuerst müssen die benötigten Namespaces und Funktionen aus den verschiedenen Libraries importiert werden. \n",
    "Um alle Funktionen aus fastai zu importieren könnte man auch das verwenden:\n",
    "```python\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "```\n",
    "Diese Methode ist jedoch eher unschön, da man den Überblick nicht hat, welche Namespaces man importiert hat. Falls man so mehrere Namespaces mit dem selbden Namen importiert, dann gewinnt der letzte. Als Beispiel: fastai hat einen Namespace mit dem Namen `Model`, welchen man hier nicht explizit gebraucht wird. Pytorch hat ebenfalls einen Namespace mit dem Namen `Model`, welcher gebraucht wird. Wenn man also `*` importiert kann es zu verwirrung führen welcher `Model`-Namespace jetzt verwendet wird oder von welcher Library dieser überhaupt kommt.\n",
    "\n",
    "Darum ist es immer besser nur explizit Namespaces und Funktionen zu importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ae75c1-c131-4f74-8976-bdf9846702bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.foundation import L\n",
    "from fastcore.xtras import Path # @patch'd properties to the Pathlib module\n",
    "\n",
    "from fastai.callback.schedule import fit_one_cycle, lr_find \n",
    "\n",
    "from fastai.data.block import CategoryBlock, DataBlock\n",
    "from fastai.data.transforms import get_image_files, RandomSplitter\n",
    "\n",
    "from fastai.learner import Learner\n",
    "\n",
    "from fastai.metrics import error_rate\n",
    "from torchvision.models.resnet import resnet34\n",
    "import torchvision.models as torch_models\n",
    "\n",
    "\n",
    "from fastai.vision.all import (\n",
    "    aug_transforms,\n",
    "    ImageBlock,\n",
    "    RegressionBlock,\n",
    "    vision_learner,\n",
    "    PILImage,\n",
    ")\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e599033f-4f77-4e6c-99a3-d78bb8ef1d74",
   "metadata": {},
   "source": [
    "# Datei-Ablage\n",
    "\n",
    "In diesem Abschnitt wird definiert, in welchem Ordner die Trainingsdaten gespeichert sind. Hier wird angenommen, das in dem Ordner immer pro Bild-Datei eine JSON-Datei mit demselben Namen befindet. Anschliessend wird überprüft, ob der Ordner existiert und das Resultat wird ausgegeben.\n",
    "\n",
    "- `image_path`: Variablenname für den Dateipfad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc3ae95-d44f-4e68-a635-e358604f1cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path('data/results/<meine_resultate>')\n",
    "image_path.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bfed02-eba3-410a-8181-403b058d069f",
   "metadata": {},
   "source": [
    "# Daten aus einer JSON-Datei auslesen\n",
    "In einem nächsten Schritt wird eine Funktion definiert, bei die nötigen Daten aus einer JSON-Datei ausliest und in einer Liste zurück gibt:\n",
    "\n",
    "```python\n",
    "def read_data_from_json(image):\n",
    "```\n",
    "\n",
    "- `image`: Ist der Posix Pfad zu dem Bild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f14ac6d-0a46-4530-8da2-5aa9f633a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_json(image):\n",
    "    with open(image_path/f'{image.stem}.json') as f:\n",
    "        json_file = json.load(f)\n",
    "        return[float(json_file['throttle']), float(json_file['steering'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f095cb-d4c6-4a9f-a60f-f3be30cfc746",
   "metadata": {},
   "source": [
    "# Testen\n",
    "\n",
    "Nun ein kruzer Test der bereits erstellen Funktionalitäten. Dafür wird ein Bild geladen als PILImage. \n",
    "So kann man ganz einfach ein PILImage aus einem bestehenden Bild erstellen und anzeigen lassen:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cf73d1-ff45-4564-880e-fe8af9eafd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = PILImage.create(image_path/'2022-10-18T14:15:52.011617.png')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de74132c-34f6-4855-bea5-cba97b7ad218",
   "metadata": {},
   "source": [
    "Als nächstes noch die `read_data_from_json` Funktion aufrufen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c5763e-d5ec-4e55-9d61-2cdb29f0f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data_from_json(Path(image_path/'2022-10-18T14:15:52.011617.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a758ae-c751-4817-bf0a-3ec165feb77a",
   "metadata": {},
   "source": [
    "# Datenblock\n",
    "\n",
    "Jetzt ist alles so vorbereitet, dass man das Training mit der AI aufsetzten kann. Um damit zu beginnen muss zuerst ein `Datablock` erstellt werden. Ein Datablock ist einfach gesagt nichts anderes als ein Packet für eine genormte Schnittstelle. Das heisst, dass es sehr einfach ist anzugeben, was für Daten sind der Input, von wo kommen diese Daten, was ist der Ziel Output etc.\n",
    "\n",
    "Da es sich hier um das Trainieren handelt werden sowohl der Erwartete Input, wie auch der dazugehörige Output benötigt.\n",
    "\n",
    "Ein Datablock erstellt man relativ einfach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e935563-92bc-4b4a-ada6-e30e041929d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_block = DataBlock(blocks=(ImageBlock, RegressionBlock(n_out=2)),\n",
    "                    get_items=get_image_files,\n",
    "                    splitter=RandomSplitter(),\n",
    "                    get_y=read_data_from_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c9fb7d-6ea3-40b7-81f6-07978d75ee82",
   "metadata": {},
   "source": [
    "- `blocks`: Definiert mit welchen Daten das Model arbeiten wird. Meistens werden mind. zwei Blöcke definiert. Der erste Block spezifiziert die Input-Daten und der zweite Block die erwarteten Output-Daten sind. In diesem Beispiel werden Bilder als Input erwartet und als Output ein RegressionBlock mit zwei Ausgabewerten. Anhand dieser Regression wird versucht einem Bild Werte zuzuweisen. Der Grund wieso es zwei Outputs hat ist, dass es einmal für die Steuerung und einmal für die Geschwindigkeit ist.\n",
    "- `get_items`: Von wo die Input-Daten gelesen werden. In diesem Fall wird die Methode `get_image_files` verwendet, welche Bilder aus einem Verzeichnis lädt.\n",
    "- `splitter`: Für das Trainieren von Daten muss bestummen werden, welche Daten für das Training und welche für die anschliessende Validierung genutzt werden. Dies kann man zufällig machen mit einem `RandomSplitter`, aber es gibt auch Methoden, wo der Nutzer dies selber definieren kann z.B. einem `FileSplitter`\n",
    "- `get_y`: Wie der Output definiert wird von den Input-Daten. Hier wird die Methode 'read_data_from_json' genutzt, beiwelcher definiert wurde, dass Anhand eines Bildes die Steuerung und das Tempo ausgelesen wird.\n",
    "- `item_tfms`: Falls Bilder zu gross sind, kann diese Methode verwendet werden, um eine Transformation auf allen Bildern auszuführen, wie z.B. zuscheiden, verkleiner, hereinzoomen etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba30f5-2dae-4d3c-9640-3faa3defb452",
   "metadata": {},
   "source": [
    "# Dataloaders\n",
    "\n",
    "Mit der fertigstellung des DataBlocks ist nun definiert, wie unsere Daten Strukturiert, Kategorisiert und Bearbeitet werden müssen. Als nächstes folg die Erstellung eines `DataLoaders`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6789e5-c1b2-4438-8286-8709a1334bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaders = data_block.dataloaders(Path(image_path), bs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfba668-c9b5-4bf5-99b7-1636c8fc1a33",
   "metadata": {},
   "source": [
    "Zuerst wird der Pfad angegeben, bei welcher der DataBlock die Bilder sucht. Die Variable `bs` steht für die Batch_Size.\n",
    "\n",
    "Ein DataLoaders ist eine Iterator-Klasse, welche vom DataBlock aufgerufen wird um die Daten in Chunks zu laden anhand der definierten Batch-Size. Also der DataLoaders erzeugt mehrere `DataLoader` Einheiten. In einem DataLoader sind die Daten dann bereits vorbereitet und ready.\n",
    "\n",
    "Man kann so ein Batch sich auch anzeigen lassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d6b72-bf44-4a6e-a8bb-2efee0963a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaders.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04e2aea-66e3-4503-aef6-cc308ddeec9d",
   "metadata": {},
   "source": [
    "# Learner\n",
    "\n",
    "Der nächste Schritt ist es eine `learner` zu erstellen. Der Learner fasst ein `Model`, mehrere `DataLoader` und eine `loss_function` zusammen in eine Methode. Die Dataloader wurden bereits erstellt, bzw. Die Iterator-Klasse `DataLoaders`.\n",
    "\n",
    "Die erste Frage ist es, welche Art von `Learner` gebraucht wird. Hier wird ein `Vision Learner` genutzt. Der Vision Learner ist ein sogenannter CNN (Convolutional Neural Network) Learner. Ein CNN ist ein Netzwerk, dass für die Erkennung und Klassifizierung von Bildern genutzt wird. Anhand von übertragbaren lernen kann dieses Netzwerk für die Bildererkennung genutzt werden.\n",
    "\n",
    "## Model\n",
    "Eine Wichtige Entscheidung, die hier getroffen werden muss, ist die Entscheidung welches `Model` vewendet werden soll. Bei einem Modell handelt es sich um ein bereits trainiertes Modell mit vielen bis zu sehr vielen Daten.\n",
    "\n",
    "Es gibt eine grosse Auswahl von verscheidenen Modellen. Die Auswahl ein richtiges Modell ist keine Einfache. Der Unterschied zwischen den Models ist, dass das Trainieren viel länger dauern kann, dafür aber je nachdem auch genauer ist. Jedoch ist das grösste Model auch nicht immer die beste Wahl, da ein grössere Modell auch für die Auswertung länger braucht.\n",
    "\n",
    "Aus diesen Gründen ist die Wahl des Modells sehr wichtig und auch keine Einfache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265f99f9-9f50-4038-9636-367e0b3c705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet34)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6ddcc9-b57e-4607-bcfb-b08417a1e3b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Learning Rate (Lern-Rate)\n",
    "\n",
    "Bevor man anfängt das Model zu trainieren muss die `learning rate` gefunden werden. Dabei ist es wichtig, dass eine gute Lern-Rate gefunden wird:\n",
    "\n",
    "- `Tiefe Lern-Rate`: Bei einer tiefen Lern-Rate dauert es länger bis das Modell einen optimalen Zustand erreicht. Das bedeutet es werden mehr Ressourcen und mehr Zeit gebraucht, als wenn man die Lern-Rate berechnet.\n",
    "- `Hohe Lern-Rate`: Bei einer hohen Lern-Rate macht das Modell oft zu grosse Schritte, was dazu führen kann, dass der optimal Zustand überschossen wird und das Modell im gegenzug and Qualität verliert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf34214-5e95-4302-8332-0fabdc9fb867",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1658d21-21a6-405c-bdaf-c782858b3acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3.630780702224001e-05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5445c86-f708-41f0-bec9-54c0c66d1606",
   "metadata": {},
   "source": [
    "Nun ist es endlich an der Zeit das Modell zu trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c808fd5-e966-45ab-8656-e96dbe4361ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(25, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df54aa8-b7d8-49a2-a8c1-d911d4e31a9d",
   "metadata": {},
   "source": [
    "Beim `fine_tune` wird sowohl der `train_loss`, wie auch der `valid_loss` angezeigt:\n",
    "\n",
    "- `train_loss`: Der Trainings-Verlust zeigt an, wie passend das Modell zu den Trainingsdaten ist. Je kleiner dieser Wert ist desto besser.\n",
    "- `valid_loss`: Der Validierungs-Verlust zeigt an, wie passend das Modell zu den neuen Daten ist. Je kleiner dieser Wert ist desto besser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271cb9c9-0452-4b0a-8163-8e95fd8daa73",
   "metadata": {},
   "source": [
    "# Fertig mit dem Training\n",
    "\n",
    "Wenn man fertig mit dem Trainieren ist, dann kann man sich auch das Resultat anzeigen lassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b674ec-08ad-4cb7-b9f7-885c764090ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(ds_idx=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82abe1-f264-446e-858a-3d680f0d772b",
   "metadata": {},
   "source": [
    "Oder auch mal ein Testbild vorhersagen lassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb202bf2-8fee-43f2-a75e-81e5dc6b926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict('<pfad>/<zum>/<Bild>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353ba28f-6188-4abe-ab4a-266b1bd56f7a",
   "metadata": {},
   "source": [
    "Oder sogar für mehrere Bilder auf einmal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3b75a6-2ff6-4eb7-8ec0-271c1f277bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_image_files('<pfad-zu-den-Bildern>')\n",
    "test_dl = learn.dls.test_dl(files)\n",
    "preds = learn.get_preds(dl=test_dl)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e2d88e-434c-4224-bf62-5a8b317670cc",
   "metadata": {},
   "source": [
    "# Exportieren der Daten\n",
    "\n",
    "Daten können ganz einfach in ein `Pickle`-File exportiert werden. So können sie später mit der `load_learner`-Funktion einfach wieder geladen werden. \n",
    "\n",
    "**Achtung** Damit der Learner wieder importiert und gebraucht werden kann müssen auch die Funktionen, die im DataBlock benutzt wurden am neuen Ort erstellt werden. In diesem Fall ist das die Funktion `read_data_from_json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198d3f9e-1687-4d94-8d6e-dd6518054039",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(Path('<Pfad>/<Modellname>.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb2731-e22e-4292-a55f-854583ec81a2",
   "metadata": {},
   "source": [
    "# Importieren\n",
    "\n",
    "Wenn der Learner importiert wurde, kann dieser wie vorhin weiter verwendet werden.\n",
    "\n",
    "In diesem Fall wird der Learner dann auf dem Fahrzeug importiert und genutzt, damit dieses so gut wie möglich selbst fahren kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1021ca58-3462-46bd-b7c5-79541a11bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner('<Pfad>/<Modellname>.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
